{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "8JlLqgvI6xcr",
    "outputId": "f759b2f0-4a91-4a98-e6e1-d4dc91b963df"
   },
   "outputs": [],
   "source": [
    "!pip3 install lime #if running for first time, uncomment this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpkW1iZ36eoY"
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import sys\n",
    "import numpy\n",
    "import pandas\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptlr_rmv6eoc"
   },
   "source": [
    "## Fetching data, training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4GpFPe86eod"
   },
   "source": [
    "In the [previous tutorial](http://marcotcr.github.io/lime-ml/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html), we looked at lime in the two class case. In this tutorial, we will use the [20 newsgroups dataset](http://scikit-learn.org/stable/datasets/#the-20-newsgroups-text-dataset) again, but this time using all of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "4pvxmIlVOWrp",
    "outputId": "396e1448-0ff7-4ca3-c282-e40c1cca8403"
   },
   "outputs": [],
   "source": [
    "# Colab stuff\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Javascript\n",
    "#%tensorflow_version 1.x\n",
    "\n",
    "!git clone -b master https://github.com/huridocs/classification-utils.git classification_utils\n",
    "\n",
    "if not 'classification_utils' in sys.path:\n",
    "  sys.path += ['classification_utils']\n",
    "\n",
    "# import python modules\n",
    "from utils import modeling, optimization, tokenization\n",
    "from utils.analysis import plot_category_distribution\n",
    "\n",
    "# gcsfs for saving dev/test set\n",
    "!pip3 install gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAaH_8nbQ5n9"
   },
   "outputs": [],
   "source": [
    "# Connect to google cloud\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-hnlw9VOfn0"
   },
   "outputs": [],
   "source": [
    "#@title Load\n",
    "from load import load_data, load_unique_labels\n",
    "from utils import io\n",
    "\n",
    "#@markdown Get possible data ids from https://github.com/huridocs/classification-utils/blob/master/config.yml\n",
    "DATA_ID = 'UHRI_affected_persons' #@param [\"UPR\", \"PlanInternational_themes\", \"PlanInternational_persons\", \"PlanInternational_paragraphs\", \"UHRI_themes\", \"UHRI_affected_persons\", \"UHRI_sdgs\", \"UPR_action\"]\n",
    "cfg_path = 'classification_utils/config.yml'\n",
    "\n",
    "data = load_data(cfg_path, DATA_ID)\n",
    "all_labels = load_unique_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "VV0RPdAxOwge",
    "outputId": "537596c0-76b8-4ad0-987a-591537a1b04d"
   },
   "outputs": [],
   "source": [
    "#@title Train/dev/test split\n",
    "\n",
    "train_fraction = 0.8 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "\n",
    "train_values = data.sample(frac=train_fraction, random_state=42)\n",
    "test_values = data.drop(train_values.index)\n",
    "\n",
    "\n",
    "print('# of total examples: {}'.format(len(data)))\n",
    "print('# of train examples: {}'.format(len(train_values)))\n",
    "print('# of test examples: {}'.format(len(test_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk93Xl0z6eod"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = train_values['text'].tolist()\n",
    "newsgroups_test = test_values['text'].tolist() \n",
    "class_names = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PSLV6e2k9oMz",
    "outputId": "e58a4b4f-393e-4d96-9775-4c4bc3032a53"
   },
   "outputs": [],
   "source": [
    "class_i = -1 # the index for the class we focus on\n",
    "specific_class = 'non-citizens' # the class name we focus on\n",
    "\n",
    "# finding the given class' index\n",
    "for i, class_name in enumerate(class_names):\n",
    "  if class_name == specific_class: \n",
    "    class_i = i\n",
    "    \n",
    "print(f'The index of {specific_class} is {class_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caScMm61AvI_"
   },
   "outputs": [],
   "source": [
    "def get_labels(one_hot_labels_list):\n",
    "  y = numpy.zeros(len(one_hot_labels_list))\n",
    "  for i in range(len(one_hot_labels_list)):\n",
    "    y[i] = one_hot_labels_list[i][class_i]\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8Malyc--ujk"
   },
   "outputs": [],
   "source": [
    "train_labels = get_labels(train_values['one_hot_labels'].to_list())\n",
    "test_labels = get_labels(test_values['one_hot_labels'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCBOVHQApzVd"
   },
   "outputs": [],
   "source": [
    "def get_count_samples_in_class(arr):\n",
    "  count = 0\n",
    "  for i in range(len(arr)):\n",
    "    if arr[i] == 1.0:\n",
    "      count = count + 1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "-PWHMbG8pSIX",
    "outputId": "36de3179-33dc-45bb-d969-896fbe8ecb16"
   },
   "outputs": [],
   "source": [
    "# get number of samples in train and test for the given class so that\n",
    "\n",
    "train_count = get_count_samples_in_class(train_labels)\n",
    "test_count = get_count_samples_in_class(test_labels)\n",
    "\n",
    "print('Class specific train count is %d' % train_count)\n",
    "print('Total train amount is %d' % len(train_labels))\n",
    "print('Class specific test count is %d' % test_count)\n",
    "print('Total test amount is %d' % len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Di0VqufL6eog",
    "outputId": "b11f0adb-81c3-433d-d94a-4f7bcf20f2f5"
   },
   "outputs": [],
   "source": [
    "print(','.join(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4cOE5_M6eoj"
   },
   "source": [
    "Again, let's use the tfidf vectorizer, commonly used for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZl61MwQ6eoj"
   },
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train)\n",
    "test_vectors = vectorizer.transform(newsgroups_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zaejd-kG6eol"
   },
   "source": [
    "This time we will use Multinomial Naive Bayes for classification, so that we can make reference to [this document](http://scikit-learn.org/stable/datasets/#filtering-text-for-more-realistic-training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "keJP0NYJ6eom",
    "outputId": "0bbf3895-4661-48db-c3eb-1a78be55ae33"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=.01)\n",
    "\n",
    "nb.fit(train_vectors, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OP8pqdYg6eoo",
    "outputId": "78974925-afd6-4a58-a5c6-a3da4a5489be"
   },
   "outputs": [],
   "source": [
    "pred = nb.predict(test_vectors)\n",
    "sklearn.metrics.f1_score(test_labels, pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnFO25j96eos"
   },
   "source": [
    "We see that this classifier achieves a very high F1 score. [The sklearn guide to 20 newsgroups](http://scikit-learn.org/stable/datasets/#filtering-text-for-more-realistic-training) indicates that Multinomial Naive Bayes overfits this dataset by learning irrelevant stuff, such as headers, by looking at the features with highest coefficients for the model in general. We now use lime to explain individual predictions instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYkVY0s26eot"
   },
   "source": [
    "## Explaining predictions using lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_pZr7IF6eot"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2Kt8L_9_6eov",
    "outputId": "3f4ee3cf-8e90-4b35-c229-1dc7d40ec38e"
   },
   "outputs": [],
   "source": [
    "print(c.predict_proba([newsgroups_test[0]]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ns5QpZkJEx2d"
   },
   "outputs": [],
   "source": [
    "# redefine classes\n",
    "class_vect = ['nothing', specific_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDc6FQ676eoy"
   },
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU8itdtn6eo1"
   },
   "source": [
    "Previously, we used the default parameter for label when generating explanation, which works well in the binary case.  \n",
    "For the multiclass case, we have to determine for which labels we will get explanations, via the 'labels' parameter.  \n",
    "Below, we generate explanations for labels 0 and 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CmAqnIzHVFeX",
    "outputId": "61c0a8fa-dd3f-46b4-d837-57a2a5b176cd"
   },
   "outputs": [],
   "source": [
    "# find the correctly classified class predictions and their indices!!\n",
    "for i, val in enumerate(test_vectors):\n",
    "  pred = int(nb.predict(val))\n",
    "  correct = int(test_labels[i])\n",
    "  if pred == 1 and correct == 1:\n",
    "    print('found a successful prediction: %d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "Xf5blOXn6eo1",
    "outputId": "1fc298ac-eb72-4cc3-d186-3b11df89986d"
   },
   "outputs": [],
   "source": [
    "idx = 41\n",
    "exp = explainer.explain_instance(newsgroups_test[idx], c.predict_proba, num_features=15, labels=[0, 1])\n",
    "print(exp.available_labels())\n",
    "print('Document id: %d' % idx)\n",
    "print('Predicted class =', class_vect[int(nb.predict(test_vectors[idx]))])\n",
    "print(f'True class: {class_vect[int(test_labels[idx])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q5dl0Cn6eo5"
   },
   "source": [
    "Now, we can see the explanations for different labels. Notice that the positive and negative signs are with respect to a particular label - so that words that are negative towards class 0 may be positive towards class 15, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "XkxSH7sv6eo5",
    "outputId": "2620d914-cde3-4bb6-bf1c-7768e9a9d233"
   },
   "outputs": [],
   "source": [
    "print('Explanation for class %s' % class_vect[0])\n",
    "print('\\n'.join(map(str, exp.as_list(label=0))))\n",
    "print()\n",
    "print('Explanation for class %s' % class_vect[1])\n",
    "print('\\n'.join(map(str, exp.as_list(label=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O3lAhwfzbRtc",
    "outputId": "60ebb12b-16e4-478b-ac05-c60486178bf0"
   },
   "outputs": [],
   "source": [
    "# SP Lime !!! \n",
    "from lime import submodular_pick\n",
    "\n",
    "sp_obj = submodular_pick.SubmodularPick(explainer, newsgroups_test, c.predict_proba, sample_size=100, num_features=10, num_exps_desired=20) # method='full'\n",
    "# can add \"method='full'\" to get explanations from entire data\n",
    "# num_exps_desired is the number of explanation objects returned\n",
    "# num_features is maximum number of features present in explanation\n",
    "# sample_size is the number of instances to explain if method == 'sample'\n",
    "# ^ default method == 'sample' will sample the data uniformly at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IwKAx1iMt2zQ",
    "outputId": "050abdd0-084d-4700-b4c2-a49ea4bcdfbb"
   },
   "outputs": [],
   "source": [
    "# shows us the features for the instances selected for one label\n",
    "[exp.as_pyplot_figure(label=exp.available_labels()[0]) for exp in sp_obj.sp_explanations]; "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practice Copy of TC + Lime - multiclass.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
